from typing import Any, Dict

import torch
import wandb

from src.datasets import TorchSimulationSequenceLoader
from src.sweep.callbacks import LoggerCallback, EarlyStoppingCallback
from src.models.config.accessors import LOSS_MAPPING, OPTIMIZER_MAPPING
from .loops import evaluate, train


class TorchSweepRunner:
    def __init__(
        self,
        model_class: torch.nn.Module,
        generator: TorchSimulationSequenceLoader,
    ) -> None:
        """
        :param model_class: The model class to use.
        :param generator: The sequence data generator to use.
        """
        self.model_class = model_class
        self.generator = generator

    def _run_experiment(self) -> None:
        """Runs a single experiment with config generated by sweep engine."""
        with wandb.init():
            parameters = wandb.config
            model = self.model_class.from_config(parameters)
            model = model.cuda()
            optimizer = OPTIMIZER_MAPPING[parameters["optimizer"]](model.parameters())
            loss = LOSS_MAPPING[parameters["loss"]]()

            model = train(
                model,
                self.generator,
                loss,
                optimizer,
                parameters["epochs"],
                callbacks=[
                    LoggerCallback(metrics=parameters["log_metrics"], log_frequency=parameters["log_frequency"]),
                    EarlyStoppingCallback(metric_name=parameters["stopping_metric"], patience=parameters["patience"]),
                ],
            )
            score = evaluate(model, self.generator)
            wandb.log(score)

    def run_sweep(self, config: Dict[str, Any], n_runs: int, project_name: str) -> None:
        """
        Runs a sweep of experiments with the given config.

        :param config: dict of sweep parameters
        :param n_runs: number of models to evaluate
        :param project_name: name of the project on wandb workspace
        """
        sweep_id = wandb.sweep(config)
        wandb.agent(sweep_id, function=self._run_experiment, count=n_runs, project=project_name)
